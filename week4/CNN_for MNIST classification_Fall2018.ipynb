{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주피터 노트북용 tqdm (progress bar 표시용)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "# 일반 python용 tqdm\n",
    "#from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self, lr=0.001):\n",
    "        # initialize convolutional filters (He initialization)\n",
    "        convF1 = np.random.randn(3, 3, 1, 16) / np.sqrt(3*3/2)     # filter size: 3x3x1  x16 channels\n",
    "        convF2 = np.random.randn(3, 3, 16, 32) / np.sqrt(3*3*16/2) # filter size: 3x3x16 x32 channels\n",
    "        \n",
    "        # initialize fully connected layer weights (He initialization)\n",
    "        fcW1 = np.random.randn(7*7*32, 512) / np.sqrt(7*7*32/2)    # shape: 1568 x 512\n",
    "        fcW2 = np.random.randn(512, 10) / np.sqrt(512/2)           # shape: 512 x 10\n",
    "        \n",
    "        # 전체 weights. 편의상 하나로 묶어서 관리\n",
    "        self.weights = np.array([convF1, convF2, fcW1, fcW2])\n",
    "        \n",
    "        # learning rate\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        # ADAM hyper-parameters\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.e = 1E-8\n",
    "        self.time_step = 0\n",
    "        # ADAM momentum & RMSProp 저장을 위한 변수\n",
    "        self.m = np.array([np.zeros(self.weights[i].shape) for i in range(len(self.weights))])\n",
    "        self.v = np.array([np.zeros(self.weights[i].shape) for i in range(len(self.weights))])\n",
    "    \n",
    "    def adam_optimization_step(self, gradient):\n",
    "        # update momentum\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "        \n",
    "        # update RMSProp\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * gradient**2\n",
    "        \n",
    "        # unbias\n",
    "        self.time_step += 1\n",
    "        m_hat = self.m / (1 - np.power(self.beta1, self.time_step))\n",
    "        v_hat = self.v / (1 - np.power(self.beta2, self.time_step))\n",
    "        \n",
    "        # update weights\n",
    "        self.weights = self.weights - self.learning_rate * m_hat / (v_hat + self.e)**0.5\n",
    "    \n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    # relu'(x)\n",
    "    def relu_dot(self, x):\n",
    "        return (x >= 0) * 1.0\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        # 지수가 너무 커지는 것을 방지하기 위해 (overflow) 최대값으로 분모, 분자를 나눔\n",
    "        e_x = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # softmax 함수의 cross entropy 손실함수 sigma { -y ln(y_pred) }\n",
    "    def cross_entropy_loss(self, y_gt, y_pred=None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.Y_pred\n",
    "        return - (y_gt * np.log(y_pred)).sum() / y_gt.shape[0]  # N개 data에 대한 평균\n",
    "    \n",
    "    def accuracy(self, y_gt, y_pred=None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.Y_pred\n",
    "        # N개 data에 대해 정답과 예측의 일치 개수 비율을 구함\n",
    "        return np.equal(y_gt.argmax(axis=1), y_pred.argmax(axis=1)).sum() / y_gt.shape[0]\n",
    "    \n",
    "    #############################\n",
    "    # convolutional function\n",
    "    def conv3x3(self, x, f):\n",
    "        # zero-padding\n",
    "        xp = np.zeros((x.shape[0], x.shape[1] +2, x.shape[2] +2, x.shape[3]))\n",
    "        xp[:, 1:-1, 1:-1, :] = x\n",
    "        \n",
    "        # convolutional operation  X:(N, W, H, C) * F:(w, h, C, D) ==> Y:(N, W, H, D)\n",
    "        y = np.zeros((x.shape[0], x.shape[1], x.shape[2], f.shape[3]))\n",
    "        for i in range(y.shape[1]):\n",
    "            for j in range(y.shape[2]):\n",
    "                # x_fraction:(N, w, h, C, 1) * f:(w, h, C, D) --> (N, w, h, C, D) \n",
    "                #  --> 2,3,4차원 합계 --> (N, 1, D)\n",
    "                #  --> W, H 만큼 반복하며 broadcasting --> (N, W, H, D)\n",
    "                y[:, i, j, :] = np.sum(xp[:, i:i+3, j:j+3, :, None] * f, axis=(1,2,3))\n",
    "        return y\n",
    "    \n",
    "    #############################\n",
    "    # convolutional backpropagation (conv. layer를 통한 error map 역전파)\n",
    "    def conv3x3_backprop(self, err_map, f):\n",
    "        # error map과 뒤집힌 filter 사이의 convolutional 연산과 동일함\n",
    "        # filter는 w(0), h(1)를 뒤집고, input channel(2)과 output channel(3)을 뒤집어야 함 (transpose(1,0,3,2))\n",
    "        return self.conv3x3(err_map, f.transpose(1,0,3,2))\n",
    "    \n",
    "    #############################\n",
    "    # convolutional filter gradient 계산\n",
    "    def conv3x3_gradient(self, err_map, x):\n",
    "        # zero-padding\n",
    "        xp = np.zeros((x.shape[0], x.shape[1] +2, x.shape[2] +2, x.shape[3]))\n",
    "        xp[:, 1:-1, 1:-1, :] = x\n",
    "        \n",
    "        # convolutional operation channel by channel  X:(N, W, H, C) * Err:(N, W, H, D) ==> F:(w, h, C, D)\n",
    "        grad_f = np.zeros((3, 3, x.shape[3], err_map.shape[3]))\n",
    "        for i in range(grad_f.shape[0]):\n",
    "            for j in range(grad_f.shape[1]):\n",
    "                # x:(N, W, H, C, 1) * err:(N, W, H, 1, D) --> (N, W, H, C, D)\n",
    "                #  --> 1,2,3차원 합계 --> (1, C, D)\n",
    "                #  --> w, h 만큼 반복 --> (w, h, C, D)\n",
    "                grad_f[i, j, :, :] = np.sum(xp[:, i:i+x.shape[1], j:j+x.shape[2], :, None] * err_map[:, :, :, None, :], axis=(0,1,2))\n",
    "        return grad_f\n",
    "    \n",
    "    #############################\n",
    "    # max-pooling function\n",
    "    def pool2x2(self, x):\n",
    "        # input 크기가 2의 배수라면 reshape와 max 함수로 구현 가능\n",
    "        return x.reshape(x.shape[0], x.shape[1]//2, 2, x.shape[2]//2, 2, x.shape[3]).max(axis=(2, 4))\n",
    "    \n",
    "    #############################\n",
    "    # max-pooling backpropagation (max-pooling layer를 통한 error map 역전파)\n",
    "    def pool2x2_backprop(self, err_map, x, y):\n",
    "        # max-pooling 출력의 dimension이 입력의 demension과 같아지도록 2x2 반복\n",
    "        # 이를 입력 값과 비교하여 값이 같다면 1, 다르다면 0으로 mask 셋팅\n",
    "        mask = np.equal(x, y.repeat(2, axis=1).repeat(2, axis=2))\n",
    "        \n",
    "        # error map 또한 입력 dimension과 같아지도록 2x2 반복\n",
    "        err_map_upscale = err_map.repeat(2, axis=1).repeat(2, axis=2)\n",
    "        \n",
    "        # error map과 mask를 (elementwise) 곱하여 error map 역전파\n",
    "        return mask * err_map_upscale\n",
    "    \n",
    "    \n",
    "    def decay_learning_rate(self, rate):\n",
    "        self.learning_rate *= rate\n",
    "        return self.learning_rate\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        # input layer\n",
    "        self.X = np.reshape(x, (-1, 28, 28, 1))             # --> (N, H=28, W=28, C=1)\n",
    "        \n",
    "        # convolutional layer 1 - relu activation\n",
    "        self.C1i = self.conv3x3(self.X, self.weights[0])    # --> (N, 28, 28, 16)\n",
    "        self.C1 = self.relu(self.C1i)\n",
    "        # max pooling layer\n",
    "        self.P1 = self.pool2x2(self.C1)                     # --> (N, 14, 14, 16)\n",
    "        \n",
    "        # convolutional layer 2 - relu activation\n",
    "        self.C2i = self.conv3x3(self.P1, self.weights[1])   # --> (N, 14, 14, 32)\n",
    "        self.C2 = self.relu(self.C2i)\n",
    "        # max pooling layer\n",
    "        self.P2 = self.pool2x2(self.C2)                     # --> (N, 7, 7, 32)\n",
    "        \n",
    "        # flatten\n",
    "        self.FL = self.P2.reshape(-1, 7*7*32)               # --> (N, 7*7*32)\n",
    "        \n",
    "        # fully connected layer - relu activation\n",
    "        self.FCi = np.dot(self.FL, self.weights[2])         # --> (N, 512)\n",
    "        self.FC = self.relu(self.FCi)\n",
    "        \n",
    "        # output layer - softmax activation\n",
    "        self.Y_pred = self.softmax(np.dot(self.FC, self.weights[3]))  # --> (N, 10)\n",
    "        return self.Y_pred\n",
    "    \n",
    "    \n",
    "    def train_step(self, x, y_gt):\n",
    "        # feedforward\n",
    "        y_pred = self.feedforward(x)\n",
    "        \n",
    "        # loss & accuracy\n",
    "        y = np.reshape(y_gt, (-1, 10))\n",
    "        ff_loss = self.cross_entropy_loss(y, y_pred)\n",
    "        ff_acc = self.accuracy(y, y_pred)\n",
    "        \n",
    "        # backpropagation\n",
    "        #  <-- output layer <--\n",
    "        errmap = (y_pred - y)                   # dL/dy * softmax_dot         # (N, 10)\n",
    "        grad_W2 = np.dot(self.FC.T, errmap)                                   # (512, 10)\n",
    "        errmap = np.dot(errmap, self.weights[3].T)                            # (N, 512) <--\n",
    "        \n",
    "        #  <-- fully connected layer <--\n",
    "        errmap = errmap * self.relu_dot(self.FCi)\n",
    "        grad_W1 = np.dot(self.FL.T, errmap)                                   # (1568, 512)\n",
    "        errmap = np.dot(errmap, self.weights[2].T).reshape(-1, 7, 7, 32)      # (N, 7, 7, 32) <--\n",
    "        \n",
    "        #  <-- max pooling layer <--\n",
    "        errmap = self.pool2x2_backprop(errmap, self.C2, self.P2)              # (N, 14, 14, 32) <--\n",
    "        \n",
    "        #  <-- convolutional layer <--\n",
    "        errmap = errmap * self.relu_dot(self.C2i)\n",
    "        grad_F2 = self.conv3x3_gradient(errmap, self.P1)                      # (3, 3, 16, 32)\n",
    "        errmap = self.conv3x3_backprop(errmap, self.weights[1])               # (N, 14, 14, 16) <--\n",
    "        \n",
    "        #  <-- max pooling layer <--\n",
    "        errmap = self.pool2x2_backprop(errmap, self.C1, self.P1)              # (N, 28, 28, 16) <--\n",
    "        \n",
    "        #  <-- convolutional layer <--\n",
    "        errmap = errmap * self.relu_dot(self.C1i)\n",
    "        grad_F1 = self.conv3x3_gradient(errmap, self.X)                       # (3, 3, 1, 16)\n",
    "        \n",
    "        # 각 gradient는 총 N(=batch_size) 개의 data에 대한 합 형태로 계산됐으므로 N으로 나누어야 함\n",
    "        num_data = y.shape[0]\n",
    "        gradients = np.array([grad_F1, grad_F2, grad_W1, grad_W2]) / num_data\n",
    "        \n",
    "        # optimization (GDM)\n",
    "        #self.weights = self.weights - self.learning_rate * gradients;\n",
    "        \n",
    "        # optimization (ADAM)\n",
    "        self.adam_optimization_step(gradients)\n",
    "        \n",
    "        # feedforward 직후 (학습 step 수행 전) loss와 accuracy 값을 return\n",
    "        return ff_loss, ff_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "epoch = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "decay_rate = 0.8\n",
    "num_training_data = 50000\n",
    "\n",
    "net = SimpleCNN(lr=learning_rate)\n",
    "\n",
    "# training data loading\n",
    "training_dataset_file = open(\"mnist_train.csv\", 'r')\n",
    "training_dataset_list = training_dataset_file.readlines()\n",
    "training_dataset_file.close()\n",
    "\n",
    "# training data의 input과 정답을 각각 list에 저장\n",
    "input_list = list()\n",
    "target_list = list()\n",
    "for i in training_dataset_list:\n",
    "    all_values = i.split(',')\n",
    "    inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "    input_list.append(inputs)\n",
    "    \n",
    "    targets = np.zeros(10) + 0.001\n",
    "    targets[int(all_values[0])] = 0.991   # sum to 1\n",
    "    target_list.append(targets)\n",
    "    \n",
    "# training, validation으로 나눔\n",
    "training_input_list = input_list[:num_training_data]\n",
    "training_target_list = target_list[:num_training_data]\n",
    "validation_input_list = input_list[num_training_data:]\n",
    "validation_target_list = target_list[num_training_data:]\n",
    "\n",
    "del(input_list)\n",
    "del(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511598a67ca1461aa8e0cc8b299c6626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87382efb838742d1bb9dc7252a81cd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.984800, loss=0.139547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c0080b9e0e47399fda2e55e5950678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d1b591fa1041449a7e3b56acb50344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.989000, loss=0.118830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e1949d510a475cad6487c138ba4280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c037f31b54cc8aafc9b4147499c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.990100, loss=0.111168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0325c89c62774c4c841c4b6cb900bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc379f07c5946d3a31ee169e3649495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.991700, loss=0.107012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4826ef50ee64f2782c0dc20183037ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3efbe8186294daea746f1b0afae9c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.993200, loss=0.102698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590b2f6553af4f718fd3b7930de7c757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0b094fb4ca41989c61183ce940beb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.992400, loss=0.100104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b603cc02b8144875b1635337f44d740b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46c9f5be5ee49d1ba6eeadf50948282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.993600, loss=0.097608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8a8a9eda284c8ea28fd9ab39f5eb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98d6859eb1a458899ee195f6cbafcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.992800, loss=0.096777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbed76f789c4a9d85ef2642852966f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5355fd472fb24e2d808b988df3212999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.993500, loss=0.095298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883bc7a25c4748d181e8e4887d8a8b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3830970632949ef9011ec87840666df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation accuracy=0.993300, loss=0.095172\n"
     ]
    }
   ],
   "source": [
    "training_loss_list = list()\n",
    "validation_loss_list = list()\n",
    "\n",
    "# 전체 반복 횟수 counting을 위한 변수\n",
    "num_iter = 0\n",
    "\n",
    "# epoch loop\n",
    "for k in range(epoch):\n",
    "    # epoch 마다 learning rate 감소\n",
    "    if k != 0:\n",
    "        learning_rate = net.decay_learning_rate(decay_rate)\n",
    "    \n",
    "    # epoch 마다 mini batch 순서 변경\n",
    "    permute_indices = np.random.permutation(len(training_input_list))\n",
    "    \n",
    "    # training용 mini batch 반복 및 progress bar 설정\n",
    "    tr = tqdm(range(0, len(training_input_list), batch_size));\n",
    "    tr.set_description('Training: %i epoch' % (k+1))\n",
    "    \n",
    "    # training loop\n",
    "    # 모든 mini batch에 대해 학습 수행\n",
    "    for i in tr:\n",
    "        batch_indices = permute_indices[i:i+batch_size]\n",
    "        x = [training_input_list[ii] for ii in batch_indices]\n",
    "        y = [training_target_list[ii] for ii in batch_indices]\n",
    "        \n",
    "        # 학습 1회 실시\n",
    "        loss, acc = net.train_step(x, y)\n",
    "        \n",
    "        # 각 반복의 training accuracy, loss, learning rate를 progress bar 화면에 표시\n",
    "        tr.set_postfix(loss=loss, accuracy=acc, learning_rate=learning_rate)\n",
    "        \n",
    "        # 그래프 출력을 위한 training loss 값 저장\n",
    "        training_loss_list.append((num_iter, loss, acc))\n",
    "        num_iter += 1\n",
    "    \n",
    "    \n",
    "    # validation용 mini batch 반복 및 progress bar 설정\n",
    "    va = tqdm(range(0, len(validation_input_list), batch_size));\n",
    "    va.set_description('Validation: %i epoch' % (k+1))\n",
    "    \n",
    "    # validation loop\n",
    "    # mini batch 단위로 수행하여 합계를 구한 후, validation data 개수로 나누어 평균을 구함\n",
    "    va_loss_sum = 0\n",
    "    va_acc_sum = 0\n",
    "    for i in va:\n",
    "        x = validation_input_list[i:i+batch_size]\n",
    "        y = validation_target_list[i:i+batch_size]\n",
    "        # feedforward\n",
    "        y_pred = net.feedforward(x)\n",
    "        y = np.reshape(y, (-1, 10))\n",
    "        # validation loss, accuracy 총합 누적\n",
    "        va_loss_sum += net.cross_entropy_loss(y, y_pred) * len(x)\n",
    "        va_acc_sum += net.accuracy(y, y_pred) * len(x)\n",
    "    \n",
    "    # validation loss, accuracy 평균 계산\n",
    "    va_loss = va_loss_sum / len(validation_input_list)\n",
    "    va_acc = va_acc_sum / len(validation_input_list)\n",
    "    print('validation accuracy=%f, loss=%f' % (va_acc, va_loss))\n",
    "    \n",
    "    # 그래프 출력을 위한 validation loss 값 저장\n",
    "    validation_loss_list.append((num_iter, va_loss, va_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233a7f791d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233a7f950f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_history = np.array(training_loss_list)\n",
    "va_history = np.array(validation_loss_list)\n",
    "\n",
    "# 학습과정에 따른 loss 변화 그래프\n",
    "# (파란색: training data, 주황색: validation data)\n",
    "fig_loss = plt.plot(tr_history[:,0], tr_history[:,1], va_history[:,0], va_history[:,1])\n",
    "plt.ylim(0, 1.5)\n",
    "plt.show(fig_loss)\n",
    "\n",
    "# 학습과정에 따른 accuracy 변화 그래프\n",
    "# (파란색: training data, 주황색: validation data)\n",
    "fig_acc = plt.plot(tr_history[:,0], tr_history[:,2], va_history[:,0], va_history[:,2])\n",
    "plt.ylim(0.6, 1)\n",
    "plt.show(fig_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test_dataset_file = open(\"mnist_test.csv\", 'r')\n",
    "test_dataset_list = test_dataset_file.readlines()\n",
    "test_dataset_file.close()\n",
    "output_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac791a2606d4708ab38f3f75dc6a2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconition error rate =  0.0067\n",
      "Reconition accuracy =  99.33 %\n"
     ]
    }
   ],
   "source": [
    "# test error rate\n",
    "success = 0\n",
    "failure = 0\n",
    "\n",
    "for i in tqdm(test_dataset_list):\n",
    "    all_values = i.split(',')\n",
    "    target = int(all_values[0])\n",
    "    \n",
    "    #inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "    prediction_list = net.feedforward(np.asfarray(all_values[1:]))\n",
    "    prediction = np.argmax(prediction_list)\n",
    "    \n",
    "    if target == prediction:\n",
    "        success = success + 1\n",
    "        #print(\"Prediction is successful. (target, predcition) = \", target, prediction)\n",
    "    else:\n",
    "        failure = failure + 1\n",
    "        #print(\"Prediction fails. (target, predcition) = \", target, prediction)\n",
    "        \n",
    "print(\"Reconition error rate = \", (failure/(success+failure)))\n",
    "print(\"Reconition accuracy = \", (success/(success+failure)) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
